# Skills Comparisons

> Quick comparison tables for decision making.

---

## üß† LLM Comparison

| Model | Context | Price | Speed | Best For |
|-------|---------|-------|-------|----------|
| GPT-4o | 128K | $$$ | Fast | General tasks |
| GPT-4 Turbo | 128K | $$$$ | Medium | Complex reasoning |
| Claude 3.5 Sonnet | 200K | $$$ | Fast | Coding, analysis |
| Claude 3 Opus | 200K | $$$$ | Slow | Deep reasoning |
| Gemini 1.5 Pro | 1M+ | $$ | Fast | Long documents |
| Llama 3.3 70B | 128K | $ | Medium | Self-hosting |
| DeepSeek V3 | 64K | $ | Fast | Coding |

**Legend:** $ = Cheap, $$$$ = Expensive

---

## üèóÔ∏è Framework Comparison

| Framework | Language | Best For | Learning Curve |
|-----------|----------|----------|----------------|
| LangChain | Python/JS | Complex workflows | ‚≠ê‚≠ê‚≠ê |
| LlamaIndex | Python/TS | RAG applications | ‚≠ê‚≠ê |
| LiteLLM | Python | Multi-provider | ‚≠ê |
| Pydantic AI | Python | Type safety | ‚≠ê‚≠ê |
| Vercel AI SDK | TS/React | Frontend apps | ‚≠ê‚≠ê |

---

## ü§ñ Agent Framework Comparison

| Framework | Multi-Agent | Type-Safe | Best Feature |
|-----------|-------------|-----------|--------------|
| CrewAI | ‚úÖ Role-based | ‚ùå Python | Easy team setup |
| AutoGen | ‚úÖ Conversational | ‚ùå Python/.NET | Microsoft ecosystem |
| LangGraph | ‚úÖ Graph-based | ‚ùå Python | State management |
| Pydantic AI | ‚ùå Single | ‚úÖ Python | Structured outputs |
| OpenAI Assistants | ‚ùå Managed | ‚úÖ Any | Quick deployment |

---

## üíæ Vector Database Comparison

| Database | Self-Host | Cloud | Best For |
|----------|-----------|-------|----------|
| Chroma | ‚úÖ | ‚úÖ | Local dev |
| Pinecone | ‚ùå | ‚úÖ | Production scale |
| Weaviate | ‚úÖ | ‚úÖ | Graph hybrid |
| Qdrant | ‚úÖ | ‚úÖ | Performance |
| pgvector | ‚úÖ | ‚úÖ | SQL apps |
| Milvus | ‚úÖ | ‚úÖ | Large scale |

---

## üîå MCP Server Installation

| Method | Command | Best For |
|--------|---------|----------|
| NPX | `npx @modelcontextprotocol/server-<name>` | Quick start |
| Smithery | `npx @smithery/cli install <id>` | Unified install |
| Docker | `docker run mcp/<name>` | Isolation |
| Python | `pip install mcp-server-<name>` | Python projects |
| Source | `git clone` | Development |

---

## üìö Learning Path by Goal

| Goal | Start With | Then Learn | Finally |
|------|------------|------------|---------|
| Build LLM apps | OpenAI API | LangChain | Production deployment |
| Create AI agents | CrewAI basics | AutoGen/LangGraph | Custom frameworks |
| Master MCP | Protocol spec | Build server | Contribute |
| Research AI | Fast.ai | Papers | Reproduce results |
| Production systems | LiteLLM | Monitoring | Cost optimization |

---

## üí∞ Cost Optimization

| Strategy | Savings | Effort |
|----------|---------|--------|
| Use local models (Ollama) | 100% | Medium |
| Caching responses | 20-40% | Low |
| Smaller models | 50-80% | Low |
| Prompt compression | 10-20% | Medium |
| Batch requests | 15-25% | Low |

---

## üîß Local Development Stack

| Component | Tool | Alternative |
|-----------|------|-------------|
| Local LLM | Ollama | LM Studio |
| Vector DB | Chroma | pgvector |
| Framework | LangChain | LlamaIndex |
| IDE | Cursor | VS Code + Continue |
| API Testing | Claude Desktop | Custom client |

---

## üöÄ Deployment Options

| Platform | Scale | Cost | Best For |
|----------|-------|------|----------|
| Modal | Serverless | Pay-per-use | Python functions |
| Vercel | Edge | Free tier | Next.js apps |
| Replicate | Model hosting | Per-run | Fast deployment |
| AWS Lambda | Serverless | Pay-per-use | Enterprise |
| Self-hosted | Unlimited | Hardware | Full control |

---

## ‚ö° Quick Decision Guide

### "I want to build..."

| Project | Recommended Stack |
|---------|-------------------|
| Chatbot | OpenAI API + Vercel AI SDK |
| RAG app | LlamaIndex + Pinecone |
| Multi-agent system | CrewAI + Claude |
| Local AI app | Ollama + LangChain |
| MCP server | TypeScript SDK |
| Research tool | Claude + MCP servers |
| Production API | LiteLLM + Modal |

---

*Use these as starting points. Your specific needs may vary!*
